{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from aicsimageio import AICSImage\n",
    "import napari\n",
    "from aicsimageio.readers import CziReader\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the image\n",
    "reader = CziReader(\"extern_Synlab_2156_17_3_MTB.czi\")\n",
    "# Get whole image\n",
    "smear = reader.get_image_data(\"MYX\", C=0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save in a new variable the information regarding the 673th tile out of 1345\n",
    "img = smear[999]\n",
    "img.shape\n",
    "\n",
    "print(img.shape)\n",
    "print(np.max(img))\n",
    "print(np.min(img))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# rescale the image to 0-255\n",
    "def rescale(image: np.ndarray):\n",
    "    \"\"\"\n",
    "    :param image: to  be rescaled\n",
    "    :return: rescaled image\n",
    "    \"\"\"\n",
    "    return (image - np.min(image)) / (np.max(image) - np.min(image)) * 255\n",
    "\n",
    "# visualize the image with napari using its numpy array\n",
    "def visualize_napari(numpy_img: np.ndarray):\n",
    "    \"\"\"\n",
    "    :param numpy_img: image to be visualized\n",
    "    \"\"\"\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.add_image(numpy_img)\n",
    "\n",
    "# visualize different images in the same moment\n",
    "def visualize_all_list_napari(numpy_img_list: np.ndarray):\n",
    "    \"\"\"\n",
    "    :param numpy_img_list: list containing different images to be visualized\n",
    "    \"\"\"\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.Viewer()\n",
    "        for img in numpy_img_list:\n",
    "            viewer.add_image(img)\n",
    "\n",
    "# plot histogram of pixel intensity\n",
    "def plot_histogram(image: np.ndarray):\n",
    "    plt.hist(image.ravel(),image.max(),[0,image.max()])\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# different thresholding methods example from opencv documentation.\n",
    "\n",
    "# global thresholding\n",
    "ret1,th1 = cv.threshold(img,5000,255,cv.THRESH_BINARY)\n",
    "# manually setting the global threshold value therefore not automatic / the optimal value / the optimal choice\n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv.GaussianBlur(img,(5,5),0)\n",
    "# blur is not really helping us here because we are looking for the opposite task.\n",
    "ret3,th3 = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "# plot all the images and their histograms\n",
    "images = [img, 0, th1,\n",
    "          img, 0, th2,\n",
    "          blur, 0, th3]\n",
    "titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n",
    "          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n",
    "          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
    "    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
    "    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
    "    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "#visualize_napari(th1)\n",
    "img = img.astype('uint8') #sbagliato\n",
    "#other thresholding methods\n",
    "img_blur = cv.medianBlur(img,5)\n",
    "ret,th1 = cv.threshold(img_blur,127,255,cv.THRESH_BINARY)\n",
    "th2 = cv.adaptiveThreshold(img_blur,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    "th3 = cv.adaptiveThreshold(img_blur,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img_blur, th1, th2, th3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute Otsu's thresholding\n",
    "def otsu_thresholding(image : np.ndarray):\n",
    "    \"\"\"\n",
    "    Threshold and binarize an image using Otsu's method\n",
    "\n",
    "    :param image: image you want to threshold\n",
    "    :return: ret: threshold value\n",
    "              th: binary image\n",
    "    \"\"\"\n",
    "    ret,th = cv.threshold(image,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    #ret is the computed value of the threshold AND th is the image with the threshold applied\n",
    "    return ret, th\n",
    "\n",
    "#compute hard thresholding\n",
    "def hard_thresholding(image : np.ndarray, threshold : int):\n",
    "    \"\"\"\n",
    "    Implement an hard threshold. Take everything above \"threshold\" to be white\n",
    "    and everything below \"threshold\" to be black\n",
    "\n",
    "    :param image: image to be thresholded\n",
    "    :param threshold: hard threshold to be implemented\n",
    "    :return: ret: threshold value\n",
    "              th: binary image\n",
    "    \"\"\"\n",
    "    ret,th = cv.threshold(image,threshold,255,cv.THRESH_BINARY)\n",
    "    return ret, th\n",
    "\n",
    "# approach for going through the different tiles and applying the thresholding separately\n",
    "# split the whole images into tiles\n",
    "def split_into_tiles(image : np.ndarray, tile_size: int):\n",
    "    \"\"\"\n",
    "    split image into tiles of shape tile_size*tile_size\n",
    "\n",
    "    :param image: image to be split\n",
    "    :param tile_size: dimensions of single tiles\n",
    "    :return: tiles: list with the different tiles\n",
    "    \"\"\"\n",
    "    tiles = []\n",
    "    for i in range(0, image.shape[0], tile_size):\n",
    "        for j in range(0, image.shape[1], tile_size):\n",
    "            tile = image[i:i+tile_size, j:j+tile_size]\n",
    "            tiles.append(tile)\n",
    "    return tiles\n",
    "\n",
    "# approach in which we sharp (in stead of blur as the example) the image before applying the thresholding\n",
    "# sharpen the image using a high-pass filter TODO: can we do this better? sharp out better maybe in sub-images?\n",
    "def sharpen(image: np.ndarray):\n",
    "    \"\"\"\n",
    "    :param image: image to be sharpened\n",
    "    :return: sharp image\n",
    "    \"\"\"\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    return cv.filter2D(image, -1, kernel)\n",
    "\n",
    "# change np array to uint8 ATENTION: in uint8 only numbers until 2^7 can be stored\n",
    "def to_uint8(image: np.ndarray):\n",
    "    return np.uint8(image)\n",
    "\n",
    "\n",
    "def find_coordinates(image: np.ndarray):\n",
    "    \"\"\"\n",
    "    Find the coordinates of the connected compenents of the image.\n",
    "    to be more specific, find first coordinate of a component\n",
    "\n",
    "    :param image: image where we want to find the connected components\n",
    "    :return: coordinates: array with coordinates of the components in the rows\n",
    "    \"\"\"\n",
    "    num_conn_comp, labels_conn_comp = cv.connectedComponents(image)\n",
    "    #num_conn_comp tells us how many components we have\n",
    "    #labels_conn_comp is an image where the entries where there should be\n",
    "    # a component are the label of that component\n",
    "    # overwritten in such a way that the the values of the pixels are the value of the corresponding connected component.\n",
    "    labels_conn_comp = labels_conn_comp.astype(np.uint64)    #cannot use uint8 cannot rappresent all numbers with uint8\n",
    "\n",
    "    #save coordinates in two dimensional array\n",
    "    coordinates = np.zeros((num_conn_comp,2),dtype=\"int64\")\n",
    "\n",
    "    # iterate over the connected components and add the coordinates of the pixels to the list of coordinates\n",
    "    for i in range(1, num_conn_comp):\n",
    "        coordinates[i,0] = np.where(labels_conn_comp == i)[0][0]\n",
    "        coordinates[i,1] = np.where(labels_conn_comp == i)[1][0]\n",
    "\n",
    "    return coordinates\n",
    "\n",
    "#connectedComponentsWithStats works better, can get centroid, in this way can put the box/rectangle around the bacilli\n",
    "#but not all conncected components are identified, might be a problem of the image we give him\n",
    "def get_connected_components_coordinate(img):\n",
    "    connectivity = 8\n",
    "    #find connected components\n",
    "    num_labels, labels_im, stats, centroids = cv.connectedComponentsWithStats(img, connectivity)\n",
    "    #get coordinates of connected components\n",
    "    coordinates = np.zeros((num_labels, 2),dtype=np.uint64)  #NO uint8\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "        coordinates[i,0] = centroids[i,0]\n",
    "        coordinates[i,1] = centroids[i,1]\n",
    "    print(coordinates)\n",
    "    return coordinates\n",
    "\n",
    "# add the 2d bounding boxes to the image\n",
    "def add_bounding_boxes(image, coordinates):\n",
    "    \"\"\"\n",
    "    Add whhite rectangles around bacilli\n",
    "\n",
    "    :param image: image with bacilli to be boxed\n",
    "    :param coordinates:  coordinates of the center of the bacillus\n",
    "    \"\"\"\n",
    "    for i in range(len(coordinates)):\n",
    "            x_min = coordinates[i][0]\n",
    "            x_max = coordinates[i][0]\n",
    "            y_min = coordinates[i][1]\n",
    "            y_max = coordinates[i][1]\n",
    "            cv.rectangle(image, (y_min+15, x_min+15), (y_max-15, x_max-15), (255, 0, 0), 4)\n",
    "\n",
    "\n",
    "#reconstruct image from different tiles given the number of tiles in x and y direction and a list of tiles\n",
    "def reconstruct_image(tiles: list, x_tiles: int, y_tiles: int):\n",
    "    \"\"\"\n",
    "    :param tiles:    list with the different single tiles\n",
    "    :param x_tiles:  how many tiles fit in the x axis\n",
    "    :param y_tiles:  how many tiles fit in the y axis\n",
    "    :return:         numpy array, reconstructed image\n",
    "    \"\"\"\n",
    "    big_image = np.zeros((x_tiles*tiles[0].shape[0], y_tiles*tiles[0].shape[1]))\n",
    "    for i in range(x_tiles):\n",
    "        for j in range(y_tiles):\n",
    "            big_image[i*tiles[0].shape[0]:(i+1)*tiles[0].shape[0], j*tiles[0].shape[1]:(j+1)*tiles[0].shape[1]] = tiles[i*y_tiles+j]\n",
    "    return big_image\n",
    "\n",
    "#find connected components with specified size with opencv using connectedComponentsWithStats\n",
    "#does not seem to work very good, maybe we do it by hand...\n",
    "#could also try with length\n",
    "def get_connected_components_with_minimum_and_max_size(img: np.ndarray(dtype= np.uint8), min_size: int,max_size: int):\n",
    "    \"\"\"\n",
    "    :param img: image where we want to find connected components. black and white immage with\n",
    "                int8 rappr.\n",
    "    :param min_size: minimum size of the cc\n",
    "    :param max_size: maximum size of the cc\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #connecctivity shoud tell us about how connected to they have to be to be considered as one, seems to be working poorly\n",
    "    connectivity = 8\n",
    "    #find connected components\n",
    "    num_labels, labels_im, stats, centroids = cv.connectedComponentsWithStats(img, connectivity)\n",
    "    #get coordinates of connected components\n",
    "    coordinates =np.array([[0,0]],dtype=np.uint64)\n",
    "    print(centroids.shape)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i,4] > min_size and stats[i,4]< max_size:\n",
    "            coordinates=np.append(coordinates,[centroids[i,:]], axis=0)\n",
    "    coordinates=coordinates[1:,:]\n",
    "    return coordinates\n",
    "\n",
    "#if a black pixel is surrounded by white pixels left right up and down we set it to white, for every pixel in the image\n",
    "#to help the connected component function, maybe we can improve this\n",
    "def remove_black_pixels_in_white(img: np.ndarray):\n",
    "    \"\"\"\n",
    "    :param img: image to be better\n",
    "    :return:    better immage with less black holes in white parts\n",
    "    \"\"\"\n",
    "    #what is white? 255 or what?\n",
    "    max=img.max()\n",
    "    #init return image\n",
    "    ret_img=np.zeros((img.shape[0],img.shape[1]))\n",
    "\n",
    "    for i in range(1,img.shape[0]-1):\n",
    "        for j in range(1,img.shape[1]-1):\n",
    "            if img[i,j] == 0:\n",
    "                if img[i-1,j] > 0 or img[i+1,j] > 0 or img[i,j-1] > 0 or img[i,j+1] > 0:\n",
    "                    ret_img[i,j] = max\n",
    "                else:\n",
    "                    ret_img[i,j]=img[i,j]\n",
    "    return ret_img\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hard_thresholding_shit_boxes(img: np.ndarray):\n",
    "    \"\"\"\n",
    "    Implement tresholding with a hard treshold (10000).\n",
    "    Find components and box coordinates, draw the boxes with\n",
    "    first coordinate of the cc.\n",
    "\n",
    "    :param img: image to be tresholded\n",
    "    \"\"\"\n",
    "    #sharpen image\n",
    "    sharpened_img = sharpen(img)\n",
    "    #hard threshold the sharpened image 10000\n",
    "    threshold, hard_threshold = hard_thresholding(sharpened_img, 10000)\n",
    "    #convert to uint8 s. t. coonected  component function can accept it\n",
    "    hard_threshold=to_uint8(hard_threshold)\n",
    "    #find coordinates of connected components, first coordinate, shit because not centered\n",
    "    coordinates= find_coordinates(hard_threshold)\n",
    "    #add bounding boxes to the image\n",
    "    add_bounding_boxes(hard_threshold,coordinates)\n",
    "    #visualize\n",
    "    visualize_all_list_napari([hard_threshold,sharpened_img,img])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def otsu_split_thresholding(img: np.ndarray):\n",
    "    \"\"\"\n",
    "    Perform Otsu tresholding on sub images of 32 x 32,\n",
    "    then reconstruct\n",
    "\n",
    "    :param img:  image to be tresholded\n",
    "    \"\"\"\n",
    "    #sharpen image\n",
    "    sharpened_img=sharpen(img)\n",
    "    #split\n",
    "    tiles=split_into_tiles(sharpened_img,32)\n",
    "    #otsu on big image\n",
    "    r_big,th_big=otsu_thresholding(sharpened_img)\n",
    "    #otsu on sub-images\n",
    "    thresholded_tiles=[]\n",
    "    for t in tiles:\n",
    "        r,th=otsu_thresholding(t)\n",
    "        thresholded_tiles.append(th)\n",
    "    #reconstruct\n",
    "    reconstructed_image=reconstruct_image(thresholded_tiles,64,47)\n",
    "    #visualize\n",
    "    visualize_all_list_napari([reconstructed_image,sharpened_img,img,th_big])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#check if image is to be set to 0, if we have more than 400 pixels with value 0 or less then 600 pixels with value 0 we set the image to 0\n",
    "def check_image(img: np.ndarray):\n",
    "    \"\"\"\n",
    "    For every sub-image we check if its worth keeping or not\n",
    "\n",
    "    :param img: image to be checked\n",
    "    :return: bool\n",
    "    \"\"\"\n",
    "    if np.sum(img == 0) > 200 and np.sum(img == 0) < 800: #maybe check for >0\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#set pixels that are 0 to 255(white)\n",
    "def set_one(img):\n",
    "    h=img\n",
    "    h[h ==0 ] = 255\n",
    "    return h\n",
    "\n",
    "#set pixels that are 255 to zero (black)\n",
    "def set_zero(img):\n",
    "    h=img\n",
    "    h[h>0]=0\n",
    "    return h\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def otsu_cleaned_white_split_thresholding(img):\n",
    "    \"\"\"\n",
    "    Performed otsu on an immage that was cleaned in white\n",
    "\n",
    "    :param img: image to be tresholded\n",
    "    :return:    tresholded clean image\n",
    "    \"\"\"\n",
    "    #sharpen image\n",
    "    sharpened_img= sharpen(img)\n",
    "    #split\n",
    "    tiles=split_into_tiles(sharpened_img,32)\n",
    "    #treshold\n",
    "    thresholded_tiles=[]\n",
    "    for t in tiles:\n",
    "        r,th_image=otsu_thresholding(t)\n",
    "        thresholded_tiles.append(th_image)\n",
    "    #reconstruct\n",
    "    reconstructed_image=reconstruct_image(thresholded_tiles,64,47)\n",
    "    #clean\n",
    "    cleaned_tiles=[]\n",
    "    for tl in thresholded_tiles:\n",
    "           if check_image(tl):\n",
    "                m=set_one(tl)\n",
    "                cleaned_tiles.append(m)\n",
    "           else:\n",
    "               cleaned_tiles.append(tl)\n",
    "    #reconstruct\n",
    "    reconstructed_clean_image=reconstruct_image(cleaned_tiles,64,47)\n",
    "    #visualize\n",
    "    visualize_all_list_napari([reconstructed_image,reconstructed_clean_image,sharpened_img,img])\n",
    "    return reconstructed_clean_image\n",
    "\n",
    "cleaned_im_white=otsu_cleaned_white_split_thresholding(img)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def otsu_cleaned_black_split_thresholding(img):\n",
    "    \"\"\"\n",
    "    Performed otsu on an immage that was cleaned in white\n",
    "\n",
    "    :param img: image to be tresholded\n",
    "    :return:    tresholded clean image\n",
    "    \"\"\"\n",
    "\n",
    "    sharpened_img= sharpen(img)\n",
    "\n",
    "    tiles=split_into_tiles(sharpened_img,32)\n",
    "\n",
    "    thresholded_tiles=[]\n",
    "    for t in tiles:\n",
    "        r,th_image=otsu_thresholding(t)\n",
    "        thresholded_tiles.append(th_image)\n",
    "    reconstructed_image=reconstruct_image(thresholded_tiles,64,47)\n",
    "\n",
    "    cleaned_tiles=[]\n",
    "    for tl in thresholded_tiles:\n",
    "           if check_image(tl):\n",
    "                m=set_zero(tl)                      #clean in black only thing that changes\n",
    "                cleaned_tiles.append(m)\n",
    "           else:\n",
    "               cleaned_tiles.append(tl)\n",
    "\n",
    "    reconstructed_clean_image=reconstruct_image(cleaned_tiles,64,47)\n",
    "\n",
    "    visualize_all_list_napari([reconstructed_image,reconstructed_clean_image,sharpened_img,img])\n",
    "\n",
    "    return reconstructed_clean_image\n",
    "\n",
    "cleaned_im_black=otsu_cleaned_black_split_thresholding(img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "cleaned_im_black=remove_black_pixels_in_white(cleaned_im_black)\n",
    "cleaned_im_black_int=to_uint8(cleaned_im_black)\n",
    "\n",
    "new_coordinates=get_connected_components_with_minimum_and_max_size(cleaned_im_black_int, 0,100000)\n",
    "\n",
    "\n",
    "new_coordinates=new_coordinates.astype(int)\n",
    "\n",
    "add_bounding_boxes(cleaned_im_black,new_coordinates)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "images = [img, cleaned_im_black]\n",
    "\n",
    "visualize_all_list_napari(images)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tub",
   "language": "python",
   "display_name": "python tub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f19abd1b44d3ababfc9655fdc4228c8b5a5e2e5f7c5710341294ee3b86695e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
