{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from aicsimageio import AICSImage\n",
    "import napari\n",
    "from aicsimageio.readers import CziReader\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#ALL USED FUNCTIONS\n",
    "\n",
    "\n",
    "#VISUALIZATION\n",
    "# visualize the image with napari using its numpy array\n",
    "def visualize_napari(numpy_img: np.ndarray, name):\n",
    "    \"\"\"\n",
    "    :param numpy_img: image to be visualized\n",
    "    \"\"\"\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.add_image(numpy_img, name=name)\n",
    "\n",
    "\n",
    "# visualize different images in the same moment\n",
    "def visualize_all_list_napari(numpy_img_list: np.ndarray, names):\n",
    "    \"\"\"\n",
    "    :param numpy_img_list: list containing different images to be visualized\n",
    "    \"\"\"\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.Viewer()\n",
    "        for i, img in enumerate(numpy_img_list):\n",
    "            viewer.add_image(img, name=names[i])\n",
    "\n",
    "\n",
    "#PREPROCESSING\n",
    "def sharpen(image: np.ndarray):\n",
    "    \"\"\"\n",
    "    Sharpen the image\n",
    "    :param image: image to be sharpened\n",
    "    :return: sharp image\n",
    "    \"\"\"\n",
    "    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "    return cv.filter2D(image, -1, kernel)\n",
    "\n",
    "\n",
    "#THRESHOLDING\n",
    "\n",
    "# compute Otsu's thresholding\n",
    "def otsu_thresholding(image: np.ndarray):\n",
    "    \"\"\"\n",
    "    Threshold and binarize an image using Otsu's method\n",
    "\n",
    "    :param image: image you want to threshold\n",
    "    :return: ret: threshold value\n",
    "              th: binary image\n",
    "    \"\"\"\n",
    "    ret, th = cv.threshold(image, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    #ret is the computed value of the threshold AND th is the image with the threshold applied\n",
    "    return ret, th\n",
    "\n",
    "\n",
    "# split the whole images into tiles\n",
    "def split_into_tiles(image: np.ndarray, tile_size: int):\n",
    "    \"\"\"\n",
    "    split image into tiles of shape tile_size*tile_size\n",
    "\n",
    "    :param image: image to be split\n",
    "    :param tile_size: dimensions of single tiles\n",
    "    :return: tiles: list with the different tiles\n",
    "    \"\"\"\n",
    "    tiles = []\n",
    "    for i in range(0, image.shape[0], tile_size):\n",
    "        for j in range(0, image.shape[1], tile_size):\n",
    "            tile = image[i:i + tile_size, j:j + tile_size]\n",
    "            tiles.append(tile)\n",
    "    return tiles\n",
    "\n",
    "\n",
    "#reconstruct image from different tiles given the number of tiles in x and y direction and a list of tiles\n",
    "def reconstruct_image(tiles: list, x_tiles: int, y_tiles: int):\n",
    "    \"\"\"\n",
    "    :param tiles:    list with the different single tiles\n",
    "    :param x_tiles:  how many tiles fit in the x axis\n",
    "    :param y_tiles:  how many tiles fit in the y axis\n",
    "    :return:         numpy array, reconstructed image\n",
    "    \"\"\"\n",
    "    big_image = np.zeros((x_tiles * tiles[0].shape[0], y_tiles * tiles[0].shape[1]))\n",
    "    for i in range(x_tiles):\n",
    "        for j in range(y_tiles):\n",
    "            big_image[i * tiles[0].shape[0]:(i + 1) * tiles[0].shape[0],\n",
    "            j * tiles[0].shape[1]:(j + 1) * tiles[0].shape[1]] = tiles[i * y_tiles + j]\n",
    "    return big_image\n",
    "\n",
    "\n",
    "def otsu_split_thresholding(img: np.ndarray, tile_size=16):\n",
    "    \"\"\"\n",
    "    Perform Otsu tresholding on sub images of 16 x 16,\n",
    "    if a tile is all white do not apply otsu\n",
    "\n",
    "    :param img:  image to be\n",
    "    :return thresholded_tiles_sharp: list with thresholded tiles, to be recomposed\n",
    "    \"\"\"\n",
    "    #sharpen image\n",
    "    sharpened_img = sharpen(img)\n",
    "    #get the maximum of the sharpened img, needed to check ig image is all white\n",
    "    max_value = sharpened_img.max()\n",
    "    #split\n",
    "    tiles_sharpened = split_into_tiles(sharpened_img, tile_size)\n",
    "    #do thresholding\n",
    "    thresholded_tiles_sharp = []\n",
    "    for i,t in enumerate(tiles_sharpened):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        r, th = otsu_thresholding(t)\n",
    "        if np.sum(th == 0) < 215 and np.sum(th == 0) > 200: #we have a bacilli: #we\n",
    "            new_t=sharpen2(t)\n",
    "            r,th_new=otsu_thresholding(new_t)\n",
    "            thresholded_tiles_sharp.append(th_new)\n",
    "        else:\n",
    "            thresholded_tiles_sharp.append(th)\n",
    "\n",
    "    for i, tile1 in enumerate(tiles_sharpened):\n",
    "        #check if mostly white #ATTENTION, im touching the og in memory. If yes set direclty to black\n",
    "        if check_all_white_tile(tile1, max_value):\n",
    "\n",
    "            thresholded_tiles_sharp[i]=set_zero(thresholded_tiles_sharp[i])\n",
    "            if i%94 !=0:\n",
    "                thresholded_tiles_sharp[i-1]=set_zero(thresholded_tiles_sharp[i-1])\n",
    "            if i%(95) !=0:\n",
    "                thresholded_tiles_sharp[i-2]=set_zero(thresholded_tiles_sharp[i-2])\n",
    "            if i%(93) !=0:\n",
    "                thresholded_tiles_sharp[i+1]=set_zero(thresholded_tiles_sharp[i+1])\n",
    "            if i%92 !=0:\n",
    "                thresholded_tiles_sharp[i+2]=set_zero(thresholded_tiles_sharp[i+2])\n",
    "            if i>94:\n",
    "                thresholded_tiles_sharp[i-94]=set_zero(thresholded_tiles_sharp[i-94])\n",
    "            if i>188:\n",
    "                thresholded_tiles_sharp[i-188]=set_zero(thresholded_tiles_sharp[i-188])\n",
    "            if i<11938:\n",
    "                thresholded_tiles_sharp[i+94]=set_zero(thresholded_tiles_sharp[i+94])\n",
    "            if i<11844:\n",
    "                 thresholded_tiles_sharp[i+188]=set_zero(thresholded_tiles_sharp[i+188])\n",
    "            #maybe add diagonals\n",
    "\n",
    "    return thresholded_tiles_sharp\n",
    "def ignore_connected_component_list(image):\n",
    "    sharpened_img = sharpen(img)\n",
    "    #get the maximum of the sharpened img, needed to check ig image is all white\n",
    "    max_value = sharpened_img.max()\n",
    "    tiles_sharpened = split_into_tiles(sharpened_img, 16)\n",
    "    list_indices_of_tiles_to_ignore=[]\n",
    "    for i, tile1 in enumerate(tiles_sharpened):\n",
    "        #check if mostly white #ATTENTION, im touching the og in memory. If yes set direclty to black\n",
    "        if check_all_white_tile(tile1, max_value):\n",
    "            list_indices_of_tiles_to_ignore.append(i)\n",
    "\n",
    "\n",
    "            if i%94 !=0:\n",
    "                list_indices_of_tiles_to_ignore.append(i-1)\n",
    "            if i%(95) !=0:\n",
    "                list_indices_of_tiles_to_ignore.append(i-2)\n",
    "\n",
    "            if i%(93) !=0:\n",
    "                list_indices_of_tiles_to_ignore.append(i+1)\n",
    "\n",
    "            if i%92 !=0:\n",
    "                list_indices_of_tiles_to_ignore.append(i+2)\n",
    "\n",
    "            if i>94:\n",
    "                list_indices_of_tiles_to_ignore.append(i-94)\n",
    "            if i>188:\n",
    "                list_indices_of_tiles_to_ignore.append(i-188)\n",
    "            if i<11938:\n",
    "                list_indices_of_tiles_to_ignore.append(i+94)\n",
    "            if i<11844:\n",
    "                list_indices_of_tiles_to_ignore.append(i+188)\n",
    "            if i>94 and i%94 !=0:\n",
    "                list_indices_of_tiles_to_ignore.append(i-95)\n",
    "            if i>94 and i%(93) !=0:\n",
    "                list_indices_of_tiles_to_ignore.append(i-93)\n",
    "            if i<11938 and i%94 !=0:\n",
    "                list_indices_of_tiles_to_ignore.append(i+93)\n",
    "            if i<11938 and i%(93) !=0:\n",
    "                list_indices_of_tiles_to_ignore.append(i+95)\n",
    "            #maybe add more to diagonal\n",
    "    return list_indices_of_tiles_to_ignore\n",
    "\n",
    "def set_to_zero_advanced():\n",
    "    return False\n",
    "\n",
    "def otsu_cleaned_split_thresholding(img):\n",
    "    \"\"\"\n",
    "    Performe otsu thresholding on 16 x 16 images, then clean the image,\n",
    "     delete the noise\n",
    "\n",
    "    :param img: image to be tresholded\n",
    "    :return:    tresholded clean image\n",
    "    \"\"\"\n",
    "\n",
    "    #list with the thresholded tiles size 16x16\n",
    "    thresholded_tiles = otsu_split_thresholding(img, 16)\n",
    "\n",
    "    #clean\n",
    "    cleaned_tiles = []\n",
    "    for tl in thresholded_tiles:\n",
    "        #check if image is not a bacilli\n",
    "        if check_image(tl):\n",
    "            #im not a bacilli\n",
    "            m = set_zero(tl)\n",
    "            cleaned_tiles.append(m)\n",
    "        else:\n",
    "            #i am a bacilli\n",
    "            cleaned_tiles.append(tl)\n",
    "\n",
    "    #reconstruct\n",
    "    reconstructed_clean_image = reconstruct_image(cleaned_tiles, 128, 94)\n",
    "\n",
    "    #final cleaning\n",
    "    #final_cleaned_image = (reconstructed_clean_image)\n",
    "\n",
    "    #visualize\n",
    "    #visualize_all_list_napari([reconstructed_image, reconstructed_clean_image,sharpened_img,img], [\"reconstructed_image\",\"reconstructed_clean_image\",\"sharpened_img\",\"img\"])\n",
    "\n",
    "    return reconstructed_clean_image\n",
    "\n",
    "\n",
    "#POSTPROCESSING\n",
    "\n",
    "def check_image(img: np.ndarray):\n",
    "    \"\"\"\n",
    "    For every sub-image we check if its worth keeping or not\n",
    "    215 pretty hard-coded---> maybe rely on scientific paper to find the optimal number\n",
    "\n",
    "    :param img: image to be checked\n",
    "    :return: bool\n",
    "    \"\"\"\n",
    "\n",
    "    if np.sum(img == 0) > 215:  #we have a bacilli\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "#set pixels that are 255 to zero (black)\n",
    "def set_zero(img):\n",
    "    h = img\n",
    "    h[h > 0] = 0\n",
    "    return h\n",
    "\n",
    "\n",
    "def check_all_white_tile(img, max_value_global):\n",
    "    \"\"\"\n",
    "    Check if we have a huge bright tile. if a 16 x 16 tile is all white--->\n",
    "    we want it black. Check based on global max pixel value\n",
    "\n",
    "    :param img: tile to be checked if white\n",
    "    :param max_value: max value pixel of whole image\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if np.sum(img > 0.2 * max_value_global) > 0.9 * img.shape[0] * img.shape[1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def clean_connected_components(img: np.ndarray):\n",
    "    \"\"\"\n",
    "    Clean image with 2 approaches: delete connected components that have are up to 2 pixels\n",
    "                                   connect bacilli that are separated by just one black pixel\n",
    "\n",
    "    :param img: image to be cleaned\n",
    "    :return:    cleaned image\n",
    "    \"\"\"\n",
    "\n",
    "    #find connected components\n",
    "    num_labels, labels_im, stats, centroids = cv.connectedComponentsWithStats(np.uint8(img), connectivity=8)\n",
    "    #stats = x,y,w,h,area\n",
    "\n",
    "    #put to black connected components which area is equal to 1 or 2\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i][4] < 3:\n",
    "            img[labels_im == i] = 0\n",
    "    #do not want to connect bacilli in original, want to connect after little components are gone\n",
    "    img2 = img.copy()\n",
    "    #connect the bacilli, by putting a white tile\n",
    "    for i in range(1, img.shape[0] - 1):\n",
    "        for j in range(1, img.shape[1] - 1):\n",
    "            if img[i, j] == 0:\n",
    "                if (img[i - 1, j] == 255 and img[i + 1, j] == 255) or (img[i, j - 1] == 255 and img[i, j + 1] == 255) \\\n",
    "                        or (img[i - 1, j - 1] == 255 and img[i + 1, j + 1]) or (\n",
    "                        img[i - 1, j + 1] == 255 and img[i + 1, j - 1] == 255) \\\n",
    "                        or (img[i - 1, j] == 255 and img[i + 1, j + 1] == 255) or (\n",
    "                        img[i - 1, j + 1] == 255 and img[i + 1, j] == 255) \\\n",
    "                        or (img[i - 1, j] == 255 and img[i + 1, j - 1] == 255) or (\n",
    "                        img[i - 1, j - 1] == 255 and img[i + 1, j] == 255) \\\n",
    "                        or (img[i, j - 1] == 255 and img[i + 1, j + 1] == 255) or (\n",
    "                        img[i, j - 1] == 255 and img[i - 1, j + 1] == 255) \\\n",
    "                        or (img[i, j + 1] == 255 and img[i + 1, j - 1] == 255) or (\n",
    "                        img[i, j + 1] == 255 and img[i - 1, j - 1] == 255):\n",
    "                    img2[i, j] = 255\n",
    "\n",
    "    return img2\n",
    "\n",
    "\n",
    "\n",
    "# add the 2d bounding boxes to the image\n",
    "def add_bounding_boxes(image, stats):\n",
    "    \"\"\"\n",
    "    Add white rectangles around bacilli, based on conected components\n",
    "\n",
    "    :param image: image with bacilli to be boxed\n",
    "    :param coordinates:  coordinates of the center of the bacillus\n",
    "    \"\"\"\n",
    "    for i in range(1, len(stats)):\n",
    "        x = stats[i][0] - 5\n",
    "        #x_max = coordinates[i][0]\n",
    "        y = stats[i][1] - 5\n",
    "        #y_max = coordinates[i][1]\n",
    "        h = stats[i][3]\n",
    "        w = stats[i][2]\n",
    "        cv.rectangle(image, (x, y), (x + w + 10, y + h + 10), (5000, 255, 255), 1)\n",
    "    return image\n",
    "\n",
    "#given image and connected componets stats find center of mass of each connected component\n",
    "def find_center_of_mass( stats):\n",
    "    center_of_mass = []\n",
    "    for i in range(1, stats.shape[0]):\n",
    "        #find center of mass\n",
    "        x = stats[i, 0]\n",
    "        y = stats[i, 1]\n",
    "        w = stats[i, 2]\n",
    "        h = stats[i, 3]\n",
    "        #find center of mass\n",
    "        center_of_mass.append((x + w//2, y + h//2))\n",
    "    return center_of_mass\n",
    "\n",
    "#given image and center of mass list give back a list of images 50x50 pixels around the center of mass\n",
    "\n",
    "def crop_images(image, center_of_mass):\n",
    "    cropped_images = []\n",
    "    for i in range(len(center_of_mass)):\n",
    "        x = center_of_mass[i][0]\n",
    "        y = center_of_mass[i][1]\n",
    "        cropped_images.append(image[y-25:y+25, x-25:x+25])\n",
    "    return cropped_images\n",
    "\n",
    "def sharpen2(img):\n",
    "    return cv.addWeighted(img, 4, cv.blur(img, (30, 30)), -4, 128)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "# detect blurry image based on fourier transform\n",
    "def is_blurry(image):\n",
    "    #convert image to grayscale\n",
    "\n",
    "    #find fourier transform\n",
    "    f = np.fft.fft2(image)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "    #find mean of magnitude spectrum\n",
    "    mean = np.mean(magnitude_spectrum)\n",
    "    #print(mean)\n",
    "    #if mean is less than 100 then image is blurry\n",
    "    if mean < 220:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "#PIPELINE (until the end)\n",
    "\n",
    "# Load the image\n",
    "reader = CziReader(\"extern_Synlab_2156_17_3_MTB.czi\")\n",
    "# Get whole image\n",
    "smear = reader.get_image_data(\"MYX\", C=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "\n",
    "# save in a new variable the information regarding the 673th tile out of 1345\n",
    "booleanimg=[]\n",
    "for i,img in enumerate(smear):\n",
    "\n",
    "    if is_blurry(img):\n",
    "        booleanimg.append(0)\n",
    "    else:\n",
    "        booleanimg.append(1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n"
     ]
    }
   ],
   "source": [
    "print(sum(booleanimg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QWindowsWindow::setGeometry: Unable to set geometry 1280x1104+0+34 (frame: 1302x1160-11-11) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 1280x1102+0+34 (frame: 1302x1158-11-11) margins: 11, 45, 11, 11 minimum size: 374x551 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=770,1158 maxtrack=0,0)\n",
      "22-Dec-22 11:22:06 - vispy    - WARNING  - QWindowsWindow::setGeometry: Unable to set geometry 1280x1104+0+34 (frame: 1302x1160-11-11) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 1280x1102+0+34 (frame: 1302x1158-11-11) margins: 11, 45, 11, 11 minimum size: 374x551 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=770,1158 maxtrack=0,0)\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.view_image(smear)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ground_t=[1,1,0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "\n",
    "#for comparison\n",
    "_, otsu_thresholded_entire_og_img = otsu_thresholding(img)\n",
    "sharpened_img = sharpen(img)\n",
    "_, otsu_thresholded_entire_sharp_img = otsu_thresholding(sharpened_img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#do split thresholding\n",
    "otsu_st_16 = reconstruct_image(otsu_split_thresholding(img, 16), 128, 94)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "\n",
    "#do split thresholding and clean noise from thresholding\n",
    "otsu_st_16_cleaned_from_noise = otsu_cleaned_split_thresholding(img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "\n",
    "#save new copy for comparison, not needed if we dont want comparison\n",
    "a_bit_of_shit_in_our_bacilli_tiles = otsu_st_16_cleaned_from_noise.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "\n",
    "#cut small connected components and connect bacilli\n",
    "cleaning_the_shit_on_the_bacilli_tiles = clean_connected_components(otsu_st_16_cleaned_from_noise)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "\n",
    "#get stats for drawing boxes\n",
    "num_labels, labels_im, stats, centroids = cv.connectedComponentsWithStats(\n",
    "    np.uint8(cleaning_the_shit_on_the_bacilli_tiles), connectivity=8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "\n",
    "#another copy----ask marina\n",
    "bacilli = otsu_st_16_cleaned_from_noise.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "\n",
    "#add the boxes\n",
    "box_bacilli = add_bounding_boxes(bacilli, stats)\n",
    "img_copy = img.copy()\n",
    "box_img = add_bounding_boxes(img_copy, stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matteo\\anaconda3\\envs\\tub\\lib\\site-packages\\napari\\_qt\\qt_event_loop.py:284: FutureWarning: \n",
      "The 'gui_qt()' context manager is deprecated.\n",
      "If you are running napari from a script, please use 'napari.run()' as follows:\n",
      "\n",
      "    import napari\n",
      "\n",
      "    viewer = napari.Viewer()  # no prior setup needed\n",
      "    # other code using the viewer...\n",
      "    napari.run()\n",
      "\n",
      "In IPython or Jupyter, 'napari.run()' is not necessary. napari will automatically\n",
      "start an interactive event loop for you: \n",
      "\n",
      "    import napari\n",
      "    viewer = napari.Viewer()  # that's it!\n",
      "\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#visualize\n",
    "visualize_all_list_napari(\n",
    "    [box_img, box_bacilli, cleaning_the_shit_on_the_bacilli_tiles, a_bit_of_shit_in_our_bacilli_tiles,\n",
    "     otsu_st_16_cleaned_from_noise, otsu_st_16, img],\n",
    "    [\"og boxes\", \"boxes\", \"no 1s and unite bacilli\", \"a bit of artifacts\", \"cleaned split otsu\", \"split otsu\", \"og\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tub",
   "language": "python",
   "display_name": "python tub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
