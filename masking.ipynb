{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicsimageio import AICSImage\n",
    "import napari\n",
    "from aicsimageio.readers import CziReader\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION\n",
    "\n",
    "# visualize the image with napari using its numpy array\n",
    "def visualize_napari(numpy_img: np.ndarray, name):\n",
    "    \"\"\"\n",
    "    :param numpy_img: image to be visualized\n",
    "    \"\"\"\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.add_image(numpy_img, name=name)\n",
    "\n",
    "\n",
    "# visualize multiple images at once\n",
    "def visualize_all_list_napari(numpy_img_list: np.ndarray, names):\n",
    "    \"\"\"\n",
    "    :param numpy_img_list: list containing different images to be visualized\n",
    "    \"\"\"\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.Viewer()\n",
    "        for i, img in enumerate(numpy_img_list):\n",
    "            viewer.add_image(img, name=names[i])\n",
    "\n",
    "\n",
    "\n",
    "# PREPROCESSING\n",
    "\n",
    "# rescale and convert image \n",
    "def rescale(image: np.ndarray):\n",
    "    \"\"\"\n",
    "    :param image: to  be rescaled\n",
    "    :return: rescaled image\n",
    "    \"\"\"\n",
    "    rescaled_image = (image - np.min(image)) / (np.max(image) - np.min(image)) * 255\n",
    "    # rescaled_image = np.round(rescaled_image).astype(np.uint16)\n",
    "    rescaled_image = np.round(rescaled_image).astype('uint8')\n",
    "    return rescaled_image\n",
    "\n",
    "\n",
    "# sharpen image\n",
    "def sharpen(image: np.ndarray):\n",
    "    \"\"\"\n",
    "    Sharpen the image\n",
    "    :param image: image to be sharpened\n",
    "    :return: sharp image\n",
    "    \"\"\"\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    return cv.filter2D(image, -1, kernel)\n",
    "\n",
    "\n",
    "\n",
    "# POSTPROCESSING \n",
    "\n",
    "# add 2D bounding boxes to the image\n",
    "def add_bounding_boxes(image, stats):\n",
    "    \"\"\"\n",
    "    Add white rectangles around bacilli, based on conected components\n",
    "\n",
    "    :param image: image with bacilli to be boxed\n",
    "    :param coordinates:  coordinates of the center of the bacillus\n",
    "    \"\"\"\n",
    "    for i in range(1,len(stats)):\n",
    "            x = stats[i][0] - 5\n",
    "            #x_max = coordinates[i][0]\n",
    "            y = stats[i][1] - 5\n",
    "            #y_max = coordinates[i][1]\n",
    "            h=stats[i][3]\n",
    "            w=stats[i][2]\n",
    "            cv.rectangle(image, (x, y), (x+w+10, y+h+10), (255, 0, 0), 1)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "reader = CziReader(\"extern_Synlab_2156_17_3_MTB.czi\")\n",
    "\n",
    "# Get whole image\n",
    "smear = reader.get_image_data(\"MYX\", C=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save 675th tile from smear in separate variable and create a copy for future purposes\n",
    "img = smear[674]\n",
    "img_copy = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16414 104\n",
      "1504 2048\n"
     ]
    }
   ],
   "source": [
    "maximum = np.max(img)\n",
    "minimum = np.min(img)\n",
    "print(maximum, minimum)\n",
    "\n",
    "wid = img.shape[1]\n",
    "hgt = img.shape[0]\n",
    "print(wid, hgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_img = rescale(img)\n",
    "sharpened_img = sharpen(rescaled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_img = cv.medianBlur(rescaled_img,1)\n",
    "th2 = cv.adaptiveThreshold(rescaled_img,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,25,-5) # negative Werte erhöhen den Schwarzanteil, positive den Weißanteil\n",
    "th3 = cv.adaptiveThreshold(rescaled_img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,25,-5)\n",
    "\n",
    "th2_copy = th2.copy()\n",
    "th3_copy = th3.copy()\n",
    "\n",
    "num_labels2, labels_im2, stats2, centroids2 = cv.connectedComponentsWithStats(th2_copy, connectivity=8)\n",
    "num_labels3, labels_im3, stats3, centroids3 = cv.connectedComponentsWithStats(th3_copy, connectivity=8)\n",
    "\n",
    "# clean from noise (setting connected components of five or less white pixels to zero)\n",
    "for i in range(1, num_labels2):\n",
    "    if stats2[i][4] < 6:\n",
    "        th2_copy[labels_im2 == i] = 0\n",
    "\n",
    "for i in range(1, num_labels3):\n",
    "    if stats3[i][4] < 6:\n",
    "        th3_copy[labels_im3 == i] = 0\n",
    "\n",
    "num_labels2, labels_im2, stats2, centroids2 = cv.connectedComponentsWithStats(th2_copy, connectivity=8)\n",
    "num_labels3, labels_im3, stats3, centroids3 = cv.connectedComponentsWithStats(th3_copy, connectivity=8)\n",
    "\n",
    "th2_boxes = add_bounding_boxes(th2_copy, stats2)\n",
    "th3_boxes = add_bounding_boxes(th3_copy, stats3)\n",
    "\n",
    "# add boxes to original image\n",
    "img_copy = img.copy()\n",
    "og_boxes2 = add_bounding_boxes(img_copy, stats2)\n",
    "img_copy = img.copy()\n",
    "og_boxes3 = add_bounding_boxes(img_copy, stats3)\n",
    "\n",
    "titles = ['Original Rescaled Image', 'Sharpened Image', 'Blurred Image', 'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding', 'Boxes Mean Thresholding', 'Boxes Gaussian Thresholding', 'Boxes OG Mean', 'Boxes OG Gaussian']\n",
    "images = [rescaled_img, sharpened_img, blurred_img, th2, th3, th2_boxes, th3_boxes, og_boxes2, og_boxes3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idabu\\.vscode\\TBProject\\.venv\\lib\\site-packages\\napari\\_qt\\qt_event_loop.py:284: FutureWarning: \n",
      "The 'gui_qt()' context manager is deprecated.\n",
      "If you are running napari from a script, please use 'napari.run()' as follows:\n",
      "\n",
      "    import napari\n",
      "\n",
      "    viewer = napari.Viewer()  # no prior setup needed\n",
      "    # other code using the viewer...\n",
      "    napari.run()\n",
      "\n",
      "In IPython or Jupyter, 'napari.run()' is not necessary. napari will automatically\n",
      "start an interactive event loop for you: \n",
      "\n",
      "    import napari\n",
      "    viewer = napari.Viewer()  # that's it!\n",
      "\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# visualize\n",
    "visualize_all_list_napari(images, titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cf0400bafce4d7edbfaf4891a12032e9db7137fe6873ee0b0e8d57dbd33a75b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
